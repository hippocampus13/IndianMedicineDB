{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for handling data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "\n",
    "#for scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "\n",
    "#for concurrency\n",
    "from queue import Queue, SimpleQueue\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import threading\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy for scraping\n",
    "\n",
    "- All of the required data is contained in a script tag which begins with the text \"window.__INITIAL_STATE__\"\n",
    "\n",
    "- First I have extracted all script tags from the soup\n",
    "\n",
    "- Then I have extracted the required script tag (by checking if it begins with the \"window.__INITIAL_STATE__\" text)\n",
    "\n",
    "- Then I perform a bit of cleaning before loading the required data as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - Each of the script tags only contain 20 of the items even though we see 30 items per page. But the remaining items are available by making requests to the next page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic \n",
    "For each label keep making requests for each page till you don't get a status 200 code (this does not seem to work, the pages which do not have any data also get a success status code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(soup, send_pages=False):\n",
    "    all_scripts=soup.find_all(\"script\")\n",
    "    \n",
    "    #extracting the script tag as a string (storing in a list)\n",
    "    all_med_data=[]\n",
    "    for script in all_scripts:\n",
    "        # to check if a script tag can be converted to a string and if the string has the \"window.__INITIAL__STATE__\"\n",
    "        if (script.string) and (\"window.__INITIAL_STATE__\" in script.string):\n",
    "            all_med_data.append(script.string)\n",
    "    json_data=all_med_data[0].replace(\"\\n    window.__INITIAL_STATE__ = \",\"\"\n",
    "                       ).replace(\";\\n    window.__STATUS_CODE__ = null;\\n\",\"\")\n",
    "    json_data=json.loads(json_data)\n",
    "\n",
    "    if send_pages:\n",
    "        return ceil(json_data['allMedicinePageReducer']['meta']['total_count']/json_data['allMedicinePageReducer']['meta']['count'])\n",
    "    \n",
    "    return(json_data['allMedicinePageReducer']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%%time\n",
    "base_url=\"https://www.1mg.com/drugs-all-medicines\"\n",
    "label=list(string.ascii_lowercase)\n",
    "page=list(range(1,1000))\n",
    "results=[]\n",
    "for i in page:\n",
    "    for j in ['a','b']:\n",
    "        response=requests.get(f'{base_url}?page={str(i)}&label={str(j)}')\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        if (response.status_code==200) and (extract_json(soup)['skus']):\n",
    "            results.append(extract_json(BeautifulSoup(response.content, \"html.parser\")))\n",
    "        else:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to implement the Producer/Consumer model for Threading using concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=Queue()\n",
    "results=SimpleQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"https://www.1mg.com/drugs-all-medicines?page=1&label=b\")\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "pages = extract_json(soup, send_pages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 32\n"
     ]
    }
   ],
   "source": [
    "#creating tasks\n",
    "base_url=\"https://www.1mg.com/drugs-all-medicines\"\n",
    "labels=list(string.ascii_lowercase)\n",
    "session = requests.session()\n",
    "# page=list(range(1,2000))\n",
    "for alpha in labels:\n",
    "    resp = session.get(f'{base_url}?page=1&label={alpha}')\n",
    "    soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "    pages = extract_json(soup, send_pages=True)\n",
    "    print(f'{alpha} {pages}')\n",
    "    for page in range(1, pages+1):\n",
    "        tasks.put(f'{base_url}?page={page}&label={alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_local = threading.local()\n",
    "\n",
    "def get_session():\n",
    "    if not hasattr(thread_local, 'session'):\n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=1&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=2&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=3&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=4&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=5&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=6&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=7&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=8&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=9&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=10&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=11&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=12&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=13&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=14&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=15&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=16&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=17&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=18&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=19&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=20&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=21&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=22&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=23&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=24&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=25&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=26&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=27&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=28&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=29&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=30&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=31&label=y\n",
      "result stored for task https://www.1mg.com/drugs-all-medicines?page=32&label=y\n"
     ]
    }
   ],
   "source": [
    "# while tasks.qsize() != 0:\n",
    "#     task = tasks.get(block=False)\n",
    "#     response = session.get(task)\n",
    "#     soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "#     if (response.status_code==200) and (extract_json(soup)['skus']):\n",
    "#         results.put(extract_json(BeautifulSoup(response.content, \"html.parser\")))\n",
    "#         print(f\"result stored for task {task}\") \n",
    "#     else:\n",
    "#         print(f'data not available for task: {task}')\n",
    "    \n",
    "def scraping_worker(tasks,results):\n",
    "    session = get_session()\n",
    "    while True:\n",
    "        try:\n",
    "            task = tasks.get(block=False)\n",
    "        except queue.Empty: #\n",
    "            print('Queue is empty! My work here is done. Exiting.')\n",
    "            return\n",
    "        tasks.task_done()\n",
    "        response=session.get(task)\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        if (response.status_code==200) and (extract_json(soup)['skus']):\n",
    "            results.put(extract_json(BeautifulSoup(response.content, \"html.parser\")))\n",
    "            print(f\"result stored for task {task}\") \n",
    "        else:\n",
    "            print(f'data not available for task: {task}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor(max_workers=4) as ex:\n",
    "    futures = [\n",
    "        ex.submit(scraping_worker, tasks, results) for _ in range(4)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all([f.done() for f in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.qsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff to record for each card - \n",
    "\n",
    "1. Id and Skuid (for future fetching of data)\n",
    "\n",
    "2. Name\n",
    "\n",
    "3. Prescription req\n",
    "    \n",
    "4. is_discontinued\n",
    "\n",
    "5. manufacturer\n",
    "\n",
    "6. Type\n",
    "\n",
    "7. Pack size\n",
    "\n",
    "8. short_composition\n",
    "\n",
    "9. rx_required.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "for i in range(0,results.qsize()):\n",
    "    result=results.get()\n",
    "    temp_df.append(pd.DataFrame([[i.get('sku_id'),\n",
    "                   i.get('name'),\n",
    "                   i.get('manufacturer_name'),\n",
    "                   i.get('type'),\n",
    "                   i.get('pack_size_label'),\n",
    "                   i.get('price'),\n",
    "                   i.get('rx_required'),\n",
    "                   i.get('short_composition'),\n",
    "                   i.get('is_discontinued')] for i in result['skus']],\n",
    "                 columns=['sku_id',\n",
    "                 'name','manufacturer_name',\n",
    "                 'type','pack_size_label',\n",
    "                 'price','rx_required',\n",
    "                 'short_composition','is_discontinued']))\n",
    "final_df=pd.concat(temp_df,axis='rows',ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25      30956\n",
       "0       67264\n",
       "4      126903\n",
       "1      145603\n",
       "7      146783\n",
       "        ...  \n",
       "195    704697\n",
       "194    708323\n",
       "106    712214\n",
       "312    719084\n",
       "212    720391\n",
       "Name: sku_id, Length: 636, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['sku_id'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f'drugs{datetime.datetime.now().strftime(\"%m-%d-%YT%H-%M\")}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
