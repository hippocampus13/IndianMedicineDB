{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for handling data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#for scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "\n",
    "#for concurrency\n",
    "from queue import Queue, SimpleQueue\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "import threading\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy for scraping\n",
    "\n",
    "- All of the required data is contained in a script tag which begins with the text \"window.__INITIAL_STATE__\"\n",
    "\n",
    "- First I have extracted all script tags from the soup\n",
    "\n",
    "- Then I have extracted the required script tag (by checking if it begins with the \"window.__INITIAL_STATE__\" text)\n",
    "\n",
    "- Then I perform a bit of cleaning before loading the required data as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - Each of the script tags only contain 20 of the items even though we see 30 items per page. But the remaining items are available by making requests to the next page "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic \n",
    "For each label keep making requests for each page till you don't get a status 200 code (this does not seem to work, the pages which do not have any data also get a success status code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(response):\n",
    "    json_data=json.loads(response.content)\n",
    "    return(json_data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%%time\n",
    "base_url=\"https://www.1mg.com/drugs-all-medicines\"\n",
    "label=list(string.ascii_lowercase)\n",
    "page=list(range(1,1000))\n",
    "results=[]\n",
    "for i in page:\n",
    "    for j in ['a','b']:\n",
    "        response=requests.get(f'{base_url}?page={str(i)}&label={str(j)}')\n",
    "        soup=BeautifulSoup(response.content, \"html.parser\")\n",
    "        if (response.status_code==200) and (extract_json(soup)['skus']):\n",
    "            results.append(extract_json(BeautifulSoup(response.content, \"html.parser\")))\n",
    "        else:\n",
    "            break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to implement the Producer/Consumer model for Threading using concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks=Queue()\n",
    "results=SimpleQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.1mg.com/pharmacy_api_gateway/v4/drug_skus/by_prefix\"\n",
    "labels = list(string.ascii_lowercase)\n",
    "session = requests.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of skus for the given alphabet\n",
    "def get_number_skus(alphabet):\n",
    "    resp = session.get(f'{base_url}?prefix_term={alphabet}&page=1&per_page=1')\n",
    "    total_count = json.loads(resp.content)['meta']['total_count']\n",
    "    return total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of pages to traverse for total sku count\n",
    "def get_number_pages(total_count, results_per_request):\n",
    "    return math.ceil(total_count/results_per_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating tasks\n",
    "results_per_request = 50 # can be 1-50\n",
    "for alpha in labels:\n",
    "    pages = get_number_pages(get_number_skus(alpha), results_per_request)\n",
    "    for page in range(1, pages+1):\n",
    "        tasks.put(f'{base_url}?prefix_term={alpha}&page={page}&per_page={results_per_request}')\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_local = threading.local()\n",
    "\n",
    "def get_session():\n",
    "    if not hasattr(thread_local, 'session'):\n",
    "        thread_local.session = requests.Session()\n",
    "    return thread_local.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "global j\n",
    "j=0\n",
    "def scraping_worker(tasks,results):\n",
    "    \n",
    "    session = get_session()\n",
    "    while True:\n",
    "        try:\n",
    "            task = tasks.get(block=False) \n",
    "        except: #\n",
    "            print('Queue is empty! My work here is done. Exiting.')\n",
    "            return\n",
    "        tasks.task_done()\n",
    "        response=session.get(task)\n",
    "        if (response.status_code==200) and (extract_json(response)['skus']):\n",
    "            results.put(extract_json(response))\n",
    "            j+=1\n",
    "            print(f\"result {j} stored\")\n",
    "        time.sleep(5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 186 ms, sys: 12 ms, total: 198 ms\n",
      "Wall time: 933 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ThreadPoolExecutor(max_workers=6) as ex:\n",
    "    futures = [\n",
    "        ex.submit(scraping_worker, tasks, results) for _ in range(6)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([f.done() for f in futures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5176"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.qsize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff to record for each card - \n",
    "\n",
    "1. Id and Skuid (for future fetching of data)\n",
    "\n",
    "2. Name\n",
    "\n",
    "3. Prescription req\n",
    "    \n",
    "4. is_discontinued\n",
    "\n",
    "5. manufacturer\n",
    "\n",
    "6. Type\n",
    "\n",
    "7. Pack size\n",
    "\n",
    "8. short_composition\n",
    "\n",
    "9. rx_required.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = []\n",
    "for i in range(0,results.qsize()):\n",
    "    result=results.get()\n",
    "    temp_df.append(pd.DataFrame([[i.get('sku_id'),\n",
    "                   i.get('name'),\n",
    "                   i.get('manufacturer_name'),\n",
    "                   i.get('type'),\n",
    "                   i.get('pack_size_label'),\n",
    "                   i.get('price'),\n",
    "                   i.get('rx_required'),\n",
    "                   i.get('short_composition'),\n",
    "                   i.get('is_discontinued')] for i in result['skus']],\n",
    "                 columns=['sku_id',\n",
    "                 'name','manufacturer_name',\n",
    "                 'type','pack_size_label',\n",
    "                 'price','rx_required',\n",
    "                 'short_composition','is_discontinued']))\n",
    "final_df=pd.concat(temp_df, axis='rows',ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3312                   A 1 5mg Tablet\n",
       "5929                 A 250 Suspension\n",
       "10016        A 3 100 mg/500 mg Tablet\n",
       "10989           A Arti 60mg Injection\n",
       "10035      A Arti L 80mg/480mg Tablet\n",
       "                     ...             \n",
       "46685               Hyzer 10mg Tablet\n",
       "46618              Hyzine 25mg Tablet\n",
       "46873                Hyzix 10mg Syrup\n",
       "47172    Hyzol D 30mg/40mg Capsule SR\n",
       "47210            Hyzolid 600mg Tablet\n",
       "Name: name, Length: 47216, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['name'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"drugs.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
